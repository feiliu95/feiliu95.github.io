<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8"> 
    <meta name="keywords" content="Fei Liu, liufei, fei liu, Liu Fei, casia, ucas, VQA, Visual Question Answering, AIGC, CV">
    <meta name="description" content="Fei Liu's home page">
    <link href="bootstrap.min.css" rel="stylesheet">
    <title>Fei Liu's Homepage</title>
</head>
<body>
    <div class="container jumbotron" style="margin-top: 20px">
        <div>
            <h3>Fei Liu (刘飞)</h3>
            <h5>
	        <a target="_blank" href="###">CV</a> / 
		<a target="_black" href="https://scholar.google.com.hk/citations?user=3MCZ3I8AAAAJ&hl=zh-CN">Google Scholar</a> /
		Email: liufei9501@qq.com | fliu.9501@outlook.com
            </h5>
            <br><br>
            <h6>
                I am currently a senior researcher at ByteDance. I obtained my Ph.D. degree from <strong>Institute of Automation,
                Chinese Academy of Sciences</strong> in 2022. My advisor is Prof. <a href="https://scholar.google.com.hk/citations?user=lWtoko4AAAAJ&hl=zh-CN">Hanqing Lu</a>
		and my co-advisor is Prof. <a href="https://scholar.google.com.hk/citations?user=sOI-S7oAAAAJ&hl=zh-CN">Jing Liu</a>.
                <!-- Before that, I graduated with Bachelor degrees in automation at Shandong University. --> 
                My research interests include AIGC, Multimodal Understanding and Generation.
            </h6>
        </div>
        <br>
        <div>
            <h3>Publications</h3><hr> 
		<strong>Selected papers. Full list in <a href="https://scholar.google.com.hk/citations?user=3MCZ3I8AAAAJ&hl=zh-CN">[Google Scholar]</a>.</strong>
            <ul>
		<li><p>
                    HAIR: Hierarchical Visual-Semantic Relational Reasoning for Video Question Answering<br>
                    <b>Fei Liu</b>, Jing Liu, Weining Wang, and Hanqing Lu<br>
                    IEEE/CVF International Conference on Computer Vision (<b>ICCV</b>), 2021<br>
	        </p></li>
		<li><p>
                    Densely Connected Attention Flow for Visual Question Answering<br>
                    <b>Fei Liu</b>, Jing Liu, Zhiwei Fang, Richang Hong, and Hanqing Lu<br>
                    International Joint Conference on Artificial Intelligence (<b>IJCAI</b>), 2019<br>
	        </p></li>
		<li><p>
                    Erasing-based Attention Learning for Visual Question Answering<br>
                    <b>Fei Liu</b>, Jing Liu, Richang Hong, and Hanqing Lu<br>
                    ACM International Conference on Multimedia (<b>ACM MM</b>), 2019<br>
	        </p></li>
            </ul>
        </div>
        <br>
        <div>
            <h3>Honors & Awards</h3><hr>
            <ul >
		<li><p>
		    National Scholarship for Postgraduate (2021)</a>
		</p></li>
		<li><p>
		    <b>No.4</b> of <a href="http://www.visualqa.org/challenge.html">Visual Question Answering (VQA) Challenge 2018</a>
		</p></li>
                <li><p>
		    <b>No.1</b> of <a href="https://places-coco2017.github.io/">COCO & Places Challenge 2017</a> in Scene Parsing track
                </p></li>
            </ul>
        </div>
        <br>
        <div>
            <h3>Professional Activities</h3><hr>
            <ul >
                <li><p>
                    Teaching assistant of Multimedia Analysis and Understanding Course in UCAS, 2020
                </p></li>
            </ul>
        </div>
    </div>
</body>
</html>
